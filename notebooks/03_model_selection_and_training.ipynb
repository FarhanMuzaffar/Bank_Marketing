{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Model Selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Overview of Algorithms Considered\n",
    "\n",
    "In this project, I explored several machine learning algorithms to build a predictive model on a processed dataset with a combination of interaction features, standardized numerical features, and one-hot encoded categorical features. The target variable is an imbalanced binary feature, with the majority class being 0.\n",
    "\n",
    "1. **Logistic Regression:**\n",
    "   - **Performance:** Logistic Regression was one of the top-performing models, achieving a training ROC AUC score of 0.823. Its ability to handle imbalanced data, coupled with its simplicity and interpretability, made it a strong candidate.\n",
    "   - **Advantages:** Works well with standardized numerical features and can handle multicollinearity. The coefficients provide insights into feature importance.\n",
    "   - **Hyperparameter Tuning:** I used GridSearch with Stratified K-Fold (number of splits = 5) to tune hyperparameters for Logistic Regression, optimizing its performance on the imbalanced data.\n",
    "\n",
    "2. **Random Forest:**\n",
    "   - **Performance:** Random Forest slightly outperformed Logistic Regression with a training ROC AUC score of 0.825. It effectively handled the imbalanced dataset and the mix of feature types.\n",
    "   - **Advantages:** Robust to overfitting, particularly useful for capturing complex interactions between features, and provides feature importance metrics.\n",
    "   - **Hyperparameter Tuning:** Similar to Logistic Regression, GridSearch with Stratified K-Fold was employed to fine-tune the hyperparameters of Random Forest, ensuring the model was well-calibrated for the task.\n",
    "\n",
    "3. **Decision Tree:**\n",
    "   - **Performance:** Decision Tree performed poorly compared to Logistic Regression and Random Forest. The model struggled with the imbalanced data and did not generalize well.\n",
    "   - **Challenges:** Tendency to overfit, especially in the presence of noise and complex feature interactions, and less effective with imbalanced datasets.\n",
    "\n",
    "4. **K-Nearest Neighbors (KNN):**\n",
    "   - **Performance:** KNN also performed poorly. The model was likely hindered by the high dimensionality introduced by the one-hot encoded features and struggled with the imbalanced target variable.\n",
    "   - **Challenges:** Computationally expensive for large datasets and high-dimensional spaces, sensitive to the choice of distance metric, and not well-suited for imbalanced data.\n",
    "\n",
    "5. **Support Vector Machine (SVM):**\n",
    "   - **Performance:** Due to the computational cost associated with SVM on this dataset, I was unable to successfully train and evaluate the model.\n",
    "   - **Challenges:** While SVM is powerful for binary classification, especially with imbalanced data, it can be computationally prohibitive on large or high-dimensional datasets.\n",
    "\n",
    "**Summary:**\n",
    "- **Best Performing Models:** Logistic Regression and Random Forest emerged as the top contenders, with very close performance in terms of ROC AUC score. Both models were fine-tuned using GridSearch with Stratified K-Fold to optimize their performance.\n",
    "- **Poor Performing Models:** Decision Tree and KNN were less effective due to overfitting and difficulty handling the dataset's complexity and imbalance.\n",
    "- **Computational Limitations:** SVM was not feasible due to the high computational cost.\n",
    "\n",
    "This thorough exploration helped identify Logistic Regression and Random Forest as the most suitable models for our task, balancing performance, interpretability, and computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41176, 77)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('../data/bank-additional/bank_processed_data.csv')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41176, 76)\n",
      "(41176,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['y'], axis=1)\n",
    "y = data['y']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train: (32940, 76)\n",
      "X Test: (8236, 76)\n",
      "Y Train: (32940,)\n",
      "Y Test: (8236,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42)\n",
    "\n",
    "print(\"X Train:\", X_train.shape)\n",
    "print(\"X Test:\", X_test.shape)\n",
    "print(\"Y Train:\", y_train.shape)\n",
    "print(\"Y Test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model:\n",
    "Train a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "baseline_model = DummyClassifier(strategy='most_frequent')\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = baseline_model.predict_proba(X_test)\n",
    "\n",
    "# Print AUC Scorel\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"AUC score: %.3f\" % roc_auc_score(y_test, y_pred[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training Models:\n",
    "Train models with default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ROC AUC Score: 0.817 +/- 0.008\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced',\n",
    "                        max_iter=10000,\n",
    "                        random_state=42)\n",
    "\n",
    "# Define the Stratified K-Fold cross-validator\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(lr,\n",
    "                         X_train, y_train, \n",
    "                         cv=stratified_kfold, \n",
    "                         scoring='roc_auc')\n",
    "\n",
    "print(f\"CV ROC AUC Score: {np.mean(scores):.3f} +/- {np.std(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ROC AUC Score: 0.686 +/- 0.011\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_model = DecisionTreeClassifier(random_state=42, \n",
    "                                    class_weight='balanced')\n",
    "\n",
    "# Define the Stratified K-Fold cross-validator\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(tree_model,\n",
    "                         X_train, y_train, \n",
    "                         cv=stratified_kfold, \n",
    "                         scoring='roc_auc')\n",
    "\n",
    "print(f\"CV ROC AUC Score: {np.mean(scores):.3f} +/- {np.std(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ROC AUC Score: 0.791 +/- 0.010\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(random_state=42, \n",
    "                                class_weight='balanced')\n",
    "\n",
    "# Define the Stratified K-Fold cross-validator\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(forest,\n",
    "                         X_train, y_train, \n",
    "                         cv=stratified_kfold, \n",
    "                         scoring='roc_auc')\n",
    "\n",
    "print(f\"CV ROC AUC Score: {np.mean(scores):.3f} +/- {np.std(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ROC AUC Score: 0.740 +/- 0.009\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the Stratified K-Fold cross-validator\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(knn,\n",
    "                         X_train, y_train, \n",
    "                         cv=stratified_kfold, \n",
    "                         scoring='roc_auc')\n",
    "\n",
    "print(f\"CV ROC AUC Score: {np.mean(scores):.3f} +/- {np.std(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ROC AUC Score: 0.794 +/- 0.008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(class_weight='balanced', random_state=1)\n",
    "\n",
    "scores = cross_val_score(svm,\n",
    "                         X_train, y_train, \n",
    "                         cv=stratified_kfold, \n",
    "                         scoring='roc_auc')\n",
    "\n",
    "print(f\"CV ROC AUC Score: {np.mean(scores):.3f} +/- {np.std(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning:\n",
    "Grid search for hyperparameter optimization of best performing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best C parameter: 1.623776739188721\n",
      "Best solver parameter: liblinear\n",
      "Best penalty parameter: l1\n",
      "Training ROC AUC: 0.8174873112286329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr = LogisticRegression(max_iter=10000, \n",
    "                        class_weight='balanced', \n",
    "                        random_state=42)\n",
    "\n",
    "# Define the Stratified K-Fold cross-validator\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the hyperparameters and their values to search\n",
    "param_grid = {'C': np.logspace(-4, 4, 20),\n",
    "              'solver': ['liblinear'],\n",
    "              'penalty': ['l2', 'l1']}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "gs = GridSearchCV(estimator=lr,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='roc_auc',\n",
    "                  cv=stratified_kfold,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs_lr = gs.fit(X_train, y_train)\n",
    "\n",
    "# best_model = gs.best_estimator_\n",
    "\n",
    "string = f\"\"\"\n",
    "Best C parameter: {gs_lr.best_params_['C']}\n",
    "Best solver parameter: {gs_lr.best_params_['solver']}\n",
    "Best penalty parameter: {gs_lr.best_params_['penalty']}\n",
    "Training ROC AUC: {gs_lr.best_score_}\n",
    "\"\"\"\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best n_estimators parameter: 300\n",
      "Best max_depth parameter: 15\n",
      "Best min_sample_split parameter: 13\n",
      "Training ROC AUC: 0.8173020725332496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Initialize Random Forest Model\n",
    "forest = RandomForestClassifier(criterion='gini', class_weight='balanced', random_state=42)\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [280, 300, 320],\n",
    "    'max_depth': [12, 15, 17],\n",
    "    'min_samples_split': [11, 13, 15]}\n",
    "\n",
    "# Define the Stratified K-Fold cross-validator\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Set up GridSearchCV with Stratified K-Fold and ROC AUC as the scoring metric\n",
    "gs = GridSearchCV(estimator=forest, \n",
    "                  param_grid=param_grid, \n",
    "                  cv=stratified_kfold, \n",
    "                  scoring='roc_auc',\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs_forest = gs.fit(X_train, y_train)\n",
    "\n",
    "string = f\"\"\"\n",
    "Best n_estimators parameter: {gs_forest.best_params_['n_estimators']}\n",
    "Best max_depth parameter: {gs_forest.best_params_['max_depth']}\n",
    "Best min_sample_split parameter: {gs_forest.best_params_['min_samples_split']}\n",
    "Training ROC AUC: {gs_forest.best_score_}\n",
    "\"\"\"\n",
    "\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_forest_model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best models\n",
    "joblib.dump(gs_lr.best_estimator_, 'best_logistic_model.joblib')\n",
    "joblib.dump(gs_forest.best_estimator_, 'best_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
