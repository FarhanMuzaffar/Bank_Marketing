{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Feature Engineering:\n",
    "\n",
    "### Purpose of feature engineering.\n",
    "\n",
    "The purpose of feature engineering in this project is to enhance the model's predictive power by creating new features that capture complex relationships within the data, which might not be evident through the original features alone. Specifically, the aim is to improve the **ROC AUC** score, ensuring that the model is better at distinguishing between the positive and negative classes, particularly given the class imbalance in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41176, 21)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"../data/bank-additional/bank-additional-full.csv\",\n",
    "                   sep=\";\")\n",
    "\n",
    "# Drop duplicate rows\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Reset index\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance before feature engineering and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X Train: (32940, 19)\n",
      "X Test: (8236, 19)\n",
      "Y Train: (32940,)\n",
      "Y Test: (8236,)\n"
     ]
    }
   ],
   "source": [
    "# Spliting original features before feature engineering into X_0 and y_0\n",
    "X = data.drop(['y', 'duration'], axis=1)\n",
    "y = data['y']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encode the target\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42)\n",
    "\n",
    "print(\"\\nX Train:\", X_train.shape)\n",
    "print(\"X Test:\", X_test.shape)\n",
    "print(\"Y Train:\", y_train.shape)\n",
    "print(\"Y Test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ROC AUC Score: 0.791 +/- 0.008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "numerical_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "binary_features = X.select_dtypes(include=['int32']).columns\n",
    "\n",
    "# Column Transformer to apply OneHotEncoder to categorical features \n",
    "# and StandardScaler to numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(\n",
    "            handle_unknown='ignore', \n",
    "            sparse_output=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Pipeline with preprocessor and Logistic Regression                                                                                        \n",
    "pipe_lr = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, \n",
    "                                      max_iter=10000,\n",
    "                                      class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Define the Stratified K-Fold cross-validator\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "scores = cross_val_score(pipe_lr,\n",
    "                         X_train, y_train, \n",
    "                         cv=stratified_kfold, \n",
    "                         scoring='roc_auc')\n",
    "\n",
    "print(f\"CV ROC AUC Score: {np.mean(scores):.3f} +/- {np.std(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_continous_features = pd.DataFrame({\n",
    "    'campaign_binned': pd.cut(\n",
    "        data['campaign'], \n",
    "        bins=5, \n",
    "        labels=['0-12', '12-23', '23-34', '34-45', '45-56']).astype('str'),\n",
    "    'previous_binned': pd.cut(\n",
    "        data['previous'], \n",
    "        bins=5, \n",
    "        labels=['one', 'two', 'three', 'four', 'five']).astype('str'),\n",
    "    'age_binned': pd.cut(\n",
    "        data['age'], \n",
    "        bins=[15, 20, 30, 40, 50, 60, 70,  np.inf], \n",
    "        labels=['15-20', '20-30', '30-40', '40-50', '50-60', '60-70', '70+']).astype('str'),\n",
    "    'pdays_binned': pd.cut(\n",
    "        data['pdays'], \n",
    "        bins=[-1, 5, 10, 15, 20, 25, 30, np.inf], \n",
    "        labels=['0-5', '5-10', '10-15', '15-20', '20-25', '25-30', 'never_contacted']).astype('str'),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_continous_binned = pd.concat([data, binned_continous_features],\n",
    "                                  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_features = pd.DataFrame({\n",
    "    'marital_job_unknown_unknown': (\n",
    "        (data['marital'] == 'unknown') & \n",
    "        (data['job'] == 'unknown')).astype(int),\n",
    "    'edu_job_basic.4y_housemaid': (\n",
    "        (data['education'] == 'basic.4y') & \n",
    "        (data['job'] == 'housemaid')).astype(int),\n",
    "    'edu_job_illiterate_self-employed': (\n",
    "        (data['education'] == 'illiterate') & \n",
    "        (data['job'] == 'self-employed')).astype(int),\n",
    "    'edu_job_illiterate_retired': (\n",
    "        (data['education'] == 'illiterate') & \n",
    "        (data['job'] == 'retired')).astype(int),\n",
    "    'edu_job_unknown_student': (\n",
    "        (data['education'] == 'unknown') & \n",
    "        (data['job'] == 'student')).astype(int),\n",
    "    'edu_job_unknown_unknown': (\n",
    "        (data['education'] == 'unknown') & \n",
    "        (data['job'] == 'unknown')).astype(int), \n",
    "    'month_job_dec_retired': (\n",
    "        (data['month'] == 'dec') & \n",
    "        (data['job'] == 'retired')).astype(int),\n",
    "    'month_job_oct_retired': (\n",
    "        (data['month'] == 'oct') & \n",
    "        (data['job'] == 'retired')).astype(int),\n",
    "    'month_job_dec_student': (\n",
    "        (data['month'] == 'dec') & \n",
    "        (data['job'] == 'student')).astype(int),\n",
    "    'month_job_sep_student': (\n",
    "        (data['month'] == 'sep') & \n",
    "        (data['job'] == 'student')).astype(int),\n",
    "    'default_job_yes_technician': (\n",
    "        (data['default'] == 'yes') & \n",
    "        (data['job'] == 'technician')).astype(int),\n",
    "    'default_job_yes_unemployed': (\n",
    "        (data['default'] == 'yes') & \n",
    "        (data['job'] == 'unemployed')).astype(int),\n",
    "    'default_edu_yes_professional': (\n",
    "        (data['default'] == 'yes') & \n",
    "        (data['education'] == 'professional.course')).astype(int),\n",
    "    'default_week_yes_tue': (\n",
    "        (data['default'] == 'yes') &\n",
    "        (data['day_of_week'] == 'tue')).astype(int),\n",
    "    'default_month_yes_aug': (\n",
    "        (data['default'] == 'yes') &\n",
    "        (data['month'] == 'aug')).astype(int),\n",
    "    'loan_housing_unknown_unknown': (\n",
    "        (data['loan'] == 'unknown') & \n",
    "        (data['housing'] == 'unknown')).astype(int),\n",
    "    'poutcome_Job_Success_Student': (\n",
    "        (data['poutcome'] == 'success') & \n",
    "        (data['job'] == 'student')).astype(int),\n",
    "    'poutcome_month_success_dec': (\n",
    "        (data['poutcome'] == 'success') & \n",
    "        (data['month'] == 'dec')).astype(int),\n",
    "    'poutcome_month_success_mar': (\n",
    "        (data['poutcome'] == 'success') & \n",
    "        (data['month'] == 'mar')).astype(int),\n",
    "    'poutcome_month_success_oct': (\n",
    "        (data['poutcome'] == 'success') & \n",
    "        (data['month'] == 'oct')).astype(int),\n",
    "    'poutcome_month_success_sep': (\n",
    "        (data['poutcome'] == 'success') & \n",
    "        (data['month'] == 'sep')).astype(int),\n",
    "    'y_month_yes_dec': (\n",
    "        (data['y'] == 'yes') & \n",
    "        (data['month'] == 'dec')).astype(int),\n",
    "    'y_month_yes_mar': (\n",
    "        (data['y'] == 'yes') & \n",
    "        (data['month'] == 'mar')).astype(int),\n",
    "    'y_poutcome_yes_success': (\n",
    "        (data['y'] == 'yes') & \n",
    "        (data['poutcome'] == 'success')).astype(int)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdays_binned_interaction_features = pd.DataFrame({\n",
    "    'pdays_binned_job_20-25_retired': (\n",
    "        (data_continous_binned['pdays_binned'] == '20-25') & \n",
    "        (data_continous_binned['job'] == 'retired')).astype(int),\n",
    "    'pdays_binned_job_10-15_student': (\n",
    "        (data_continous_binned['pdays_binned'] == '10-15') & \n",
    "        (data_continous_binned['job'] == 'student')).astype(int),\n",
    "    'pdays_binned_job_15-20_student': (\n",
    "        (data_continous_binned['pdays_binned'] == '15-20') & \n",
    "        (data_continous_binned['job'] == 'student')).astype(int),\n",
    "    'pdays_binnned_job_5-10_student': (\n",
    "        (data_continous_binned['pdays_binned'] == '5-10') & \n",
    "        (data_continous_binned['job'] == 'student')).astype(int),\n",
    "    'pdays_binned_job_25-30_technician': (\n",
    "        (data_continous_binned['pdays_binned'] == '25-30') & \n",
    "        (data_continous_binned['job'] == 'technician')).astype(int),\n",
    "    'pdays_binned_marital_15-20_unknown': (\n",
    "        (data_continous_binned['pdays_binned'] == '15-20') & \n",
    "        (data_continous_binned['marital'] == 'unknown')).astype(int),\n",
    "    'pdays_binned_edu_15-20_unknown': (\n",
    "        (data_continous_binned['pdays_binned'] == '15-20') & \n",
    "        (data_continous_binned['education'] == 'unknown')).astype(int),\n",
    "    'pdays_binned_edu_25-30_professional': (\n",
    "        (data_continous_binned['pdays_binned'] == '25-30') & \n",
    "        (data_continous_binned['education'] == 'professional.course')).astype(int),\n",
    "    'pdays_binned_month_0-5_oct': (\n",
    "        (data_continous_binned['pdays_binned'] == '0-5') & \n",
    "        (data_continous_binned['month'] == 'oct')).astype(int),\n",
    "    'pdays_binned_month_0-5_sep': (\n",
    "        (data_continous_binned['pdays_binned'] == '0-5') & \n",
    "        (data_continous_binned['month'] == 'sep')).astype(int),\n",
    "    'pdays_binned_month_10-15_mar': (\n",
    "        (data_continous_binned['pdays_binned'] == '10-15') & \n",
    "        (data_continous_binned['month'] == 'mar')).astype(int),\n",
    "    'pdays_binned_month_15-20_oct': (\n",
    "        (data_continous_binned['pdays_binned'] == '15-20') & \n",
    "        (data_continous_binned['month'] == 'oct')).astype(int),\n",
    "    'pdays_binned_month_15-20_sep': (\n",
    "        (data_continous_binned['pdays_binned'] == '15-20') & \n",
    "        (data_continous_binned['month'] == 'sep')).astype(int),\n",
    "    'pdays_binned_month_20-25_mar': (\n",
    "        (data_continous_binned['pdays_binned'] == '20-25') & \n",
    "        (data_continous_binned['month'] == 'mar')).astype(int),\n",
    "    'pdays_binned_month_20-25_sep': (\n",
    "        (data_continous_binned['pdays_binned'] == '20-25') & \n",
    "        (data_continous_binned['month'] == 'sep')).astype(int),\n",
    "    'pdays_binned_month_25-30_oct': (\n",
    "        (data_continous_binned['pdays_binned'] == '25-30') & \n",
    "        (data_continous_binned['month'] == 'oct')).astype(int),\n",
    "    'pdays_binned_month_5-10_dec': (\n",
    "        (data_continous_binned['pdays_binned'] == '5-10') & \n",
    "        (data_continous_binned['month'] == 'dec')).astype(int),\n",
    "    'pdays_binned_month_5-10_mar': (\n",
    "        (data_continous_binned['pdays_binned'] == '5-10') & \n",
    "        (data_continous_binned['month'] == 'mar')).astype(int),\n",
    "    'pdays_binned_month_5-10_oct': (\n",
    "        (data_continous_binned['pdays_binned'] == '5-10') & \n",
    "        (data_continous_binned['month'] == 'oct')).astype(int),\n",
    "    'pdays_binned_month_5-10_sep': (\n",
    "        (data_continous_binned['pdays_binned'] == '5-10') & \n",
    "        (data_continous_binned['month'] == 'sep')).astype(int),\n",
    "    'pdays_binned_poutcome_0-5_success': (\n",
    "        (data_continous_binned['pdays_binned'] == '0-5') & \n",
    "        (data_continous_binned['poutcome'] == 'success')).astype(int),\n",
    "    'pdays_binned_poutcome_10-15_success': (\n",
    "        (data_continous_binned['pdays_binned'] == '10-15') & \n",
    "        (data_continous_binned['poutcome'] == 'success')).astype(int),\n",
    "    'pdays_binned_poutcome_15-20_failure': (\n",
    "        (data_continous_binned['pdays_binned'] == '15-20') & \n",
    "        (data_continous_binned['poutcome'] == 'failure')).astype(int),\n",
    "    'pdays_binned_poutcome_15-20_success': (\n",
    "        (data_continous_binned['pdays_binned'] == '15-20') & \n",
    "        (data_continous_binned['poutcome'] == 'success')).astype(int),\n",
    "    'pdays_binned_poutcome_20-25_failure': (\n",
    "        (data_continous_binned['pdays_binned'] == '20-25') & \n",
    "        (data_continous_binned['poutcome'] == 'failure')).astype(int),\n",
    "    'pdays_binned_poutcome_20-25_success': (\n",
    "        (data_continous_binned['pdays_binned'] == '20-25') & \n",
    "        (data_continous_binned['poutcome'] == 'success')).astype(int),\n",
    "    'pdays_binned_poutcome_25-30_success': (\n",
    "        (data_continous_binned['pdays_binned'] == '25-30') & \n",
    "        (data_continous_binned['poutcome'] == 'success')).astype(int),\n",
    "    'pdays_binned_poutcome_5-10_success': (\n",
    "        (data_continous_binned['pdays_binned'] == '5-10') & \n",
    "        (data_continous_binned['poutcome'] == 'success')).astype(int),\n",
    "    'pdays_binned_0-5_yes': (\n",
    "        (data_continous_binned['pdays_binned'] == '0-5') &\n",
    "        (data['y'] == 'yes')).astype(int),\n",
    "    'pdays_binned_10-15_yes': (\n",
    "        (data_continous_binned['pdays_binned'] == '10-15') &\n",
    "        (data['y'] == 'yes')).astype(int),\n",
    "    'pdays_binned_20-25_yes': (\n",
    "        (data_continous_binned['pdays_binned'] == '20-25') &\n",
    "        (data['y'] == 'yes')).astype(int),\n",
    "    'pdays_binned_25-30_yes': (\n",
    "        (data_continous_binned['pdays_binned'] == '25-30') &\n",
    "        (data['y'] == 'yes')).astype(int),\n",
    "    'pdays_binned_5-10_yes': (\n",
    "        (data_continous_binned['pdays_binned'] == '5-10') &\n",
    "        (data['y'] == 'yes')).astype(int),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_binned_interaction_feaures = pd.DataFrame({\n",
    "    'campaign_binned_marital_12-23_unknown': (\n",
    "        (data_continous_binned['campaign_binned'] == '12-23') & \n",
    "        (data_continous_binned['marital'] == 'unknown')).astype(int),\n",
    "    'campaign_binned_default_45-56_unknown': (\n",
    "        (data_continous_binned['campaign_binned'] == '45-56') & \n",
    "        (data_continous_binned['default'] == 'unknown')).astype(int),\n",
    "    'campaign_binned_housing_45-56_unknown': (\n",
    "        (data_continous_binned['campaign_binned'] == '45-56') & \n",
    "        (data_continous_binned['housing'] == 'unknown')).astype(int),\n",
    "    'campaign_binned_loan_45-56_unknown': (\n",
    "        (data_continous_binned['campaign_binned'] == '45-56') & \n",
    "        (data_continous_binned['loan'] == 'unknown')).astype(int),\n",
    "    'campaign_binned_day_of_week_45-56_unknown': (\n",
    "        (data_continous_binned['campaign_binned'] == '45-56') & \n",
    "        (data_continous_binned['day_of_week'] == 'mon')).astype(int)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_binned_interaction_features = pd.DataFrame({\n",
    "    'previous_binned_job_five_mngmnt': (\n",
    "        (data_continous_binned['previous_binned'] == 'five') & \n",
    "        (data_continous_binned['job'] == 'management')).astype(int),\n",
    "    'previous_binned_job_five_retired': (\n",
    "        (data_continous_binned['previous_binned'] == 'five') & \n",
    "        (data_continous_binned['job'] == 'retired')).astype(int),\n",
    "    'previous_binned_job_four_student': (\n",
    "        (data_continous_binned['previous_binned'] == 'four') & \n",
    "        (data_continous_binned['job'] == 'student')).astype(int),\n",
    "    'previous_binned_job_three_student': (\n",
    "        (data_continous_binned['previous_binned'] == 'three') & \n",
    "        (data_continous_binned['job'] == 'student')).astype(int),\n",
    "    'previous_binned_job_two_student': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['job'] == 'student')).astype(int),\n",
    "    'previous_binned_month_five_nov': (\n",
    "        (data_continous_binned['previous_binned'] == 'five') & \n",
    "        (data_continous_binned['month'] == 'nov')).astype(int),\n",
    "    'previous_binned_month_four_sep': (\n",
    "        (data_continous_binned['previous_binned'] == 'four') & \n",
    "        (data_continous_binned['month'] == 'sep')).astype(int),\n",
    "    'previous_binned_month_three_mar': (\n",
    "        (data_continous_binned['previous_binned'] == 'three') & \n",
    "        (data_continous_binned['month'] == 'mar')).astype(int),\n",
    "    'previous_binned_month_three_oct': (\n",
    "        (data_continous_binned['previous_binned'] == 'three') & \n",
    "        (data_continous_binned['month'] == 'oct')).astype(int),\n",
    "    'previous_binned_month_three_sep': (\n",
    "        (data_continous_binned['previous_binned'] == 'three') & \n",
    "        (data_continous_binned['month'] == 'sep')).astype(int),\n",
    "    'previous_binned_month_two_dec': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['month'] == 'dec')).astype(int),\n",
    "    'previous_binned_month_two_mar': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['month'] == 'mar')).astype(int),\n",
    "    'previous_binned_month_two_oct': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['month'] == 'oct')).astype(int),\n",
    "    'previous_binned_month_two_sep': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['month'] == 'sep')).astype(int),\n",
    "    'previous_binned_poutcome_five_success': (\n",
    "        (data_continous_binned['previous_binned'] == 'five') & \n",
    "        (data_continous_binned['poutcome'] == 'success')).astype(int),\n",
    "    'previous_binned_poutcome_four_success': (\n",
    "        (data_continous_binned['previous_binned'] == 'four') & \n",
    "        (data_continous_binned['poutcome'] == 'success')).astype(int),\n",
    "    'previous_binned_poutcome_three_failure': (\n",
    "        (data_continous_binned['previous_binned'] == 'three') & \n",
    "        (data_continous_binned['poutcome'] == 'failure')).astype(int),\n",
    "    'previous_binned_poutcome_three_success': (\n",
    "        (data_continous_binned['previous_binned'] == 'three') & \n",
    "        (data_continous_binned['poutcome'] == 'success')).astype(int),\n",
    "    'previous_binned_poutcome_two_failure': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['poutcome'] == 'failure')).astype(int),\n",
    "    'previous_binned_poutcome_two_success': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['poutcome'] == 'success')).astype(int),\n",
    "    'previous_binned_age_binned_five_60-70': (\n",
    "        (data_continous_binned['previous_binned'] == 'five') & \n",
    "        (data_continous_binned['age_binned'] == '60-70')).astype(int),\n",
    "    'previous_binned_age_binned_five_70+': (\n",
    "        (data_continous_binned['previous_binned'] == 'five') & \n",
    "        (data_continous_binned['age_binned'] == '70+')).astype(int),\n",
    "    'previous_binned_age_binned_four_15-20': (\n",
    "        (data_continous_binned['previous_binned'] == 'four') & \n",
    "        (data_continous_binned['age_binned'] == '15-20')).astype(int),\n",
    "    'previous_binned_age_binned_four_60-70': (\n",
    "        (data_continous_binned['previous_binned'] == 'four') & \n",
    "        (data_continous_binned['age_binned'] == '60-70')).astype(int),\n",
    "    'previous_binned_age_binned_three_15-20': (\n",
    "        (data_continous_binned['previous_binned'] == 'three') & \n",
    "        (data_continous_binned['age_binned'] == '15-20')).astype(int),\n",
    "    'previous_binned_age_binned_three_60-70': (\n",
    "        (data_continous_binned['previous_binned'] == 'three') & \n",
    "        (data_continous_binned['age_binned'] == '60-70')).astype(int),\n",
    "    'previous_binned_age_binned_three_70+': (\n",
    "        (data_continous_binned['previous_binned'] == 'three') & \n",
    "        (data_continous_binned['age_binned'] == '70+')).astype(int),\n",
    "    'previous_binned_age_binned_two_15-20': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['age_binned'] == '15-20')).astype(int),\n",
    "    'previous_binned_age_binned_two_60-70': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['age_binned'] == '60-70')).astype(int),\n",
    "    'previous_binned_age_binned_two_70+': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['age_binned'] == '70+')).astype(int),\n",
    "    'previous_binned_pdays_binned_five_0-5': (\n",
    "        (data_continous_binned['previous_binned'] == 'five') & \n",
    "        (data_continous_binned['pdays_binned'] == '0-5')).astype(int),\n",
    "    'previous_binned_pdays_binned_four_0-5': (\n",
    "        (data_continous_binned['previous_binned'] == 'four') & \n",
    "        (data_continous_binned['pdays_binned'] == '0-5')).astype(int),\n",
    "    'previous_binned_pdays_binned_four_20-25': (\n",
    "        (data_continous_binned['previous_binned'] == 'four') & \n",
    "        (data_continous_binned['pdays_binned'] == '20-25')).astype(int),\n",
    "    'previous_binned_pdays_binned_four_5-10': (\n",
    "        (data_continous_binned['previous_binned'] == 'four') & \n",
    "        (data_continous_binned['pdays_binned'] == '5-10')).astype(int),\n",
    "    'previous_binned_pdays_binned_three_0-5': (\n",
    "        (data_continous_binned['previous_binned'] == 'three') & \n",
    "        (data_continous_binned['pdays_binned'] == '0-5')).astype(int),\n",
    "    'previous_binned_pdays_binned_three_10-15': (\n",
    "        (data_continous_binned['previous_binned'] == 'three') & \n",
    "        (data_continous_binned['pdays_binned'] == '10-15')).astype(int),\n",
    "    'previous_binned_pdays_binned_three_15-20': (\n",
    "        (data_continous_binned['previous_binned'] == 'three') & \n",
    "        (data_continous_binned['pdays_binned'] == '15-20')).astype(int),\n",
    "    'previous_binned_pdays_binned_three_5-10': (\n",
    "        (data_continous_binned['previous_binned'] == 'three') & \n",
    "        (data_continous_binned['pdays_binned'] == '5-10')).astype(int),\n",
    "    'previous_binned_pdays_binned_two_0-5': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['pdays_binned'] == '0-5')).astype(int),\n",
    "    'previous_binned_pdays_binned_two_10-15': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['pdays_binned'] == '10-15')).astype(int),\n",
    "    'previous_binned_pdays_binned_two_15-20': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['pdays_binned'] == '15-20')).astype(int),\n",
    "    'previous_binned_pdays_binned_two_20-25': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['pdays_binned'] == '20-25')).astype(int),\n",
    "    'previous_binned_pdays_binned_two_5-10': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') & \n",
    "        (data_continous_binned['pdays_binned'] == '5-10')).astype(int),\n",
    "    'previous_binned_y_5_yes': (\n",
    "        (data_continous_binned['previous_binned'] == 'five') &\n",
    "        (data_continous_binned['y'] == 'yes')).astype(int),\n",
    "    'previous_binned_y_4_yes': (\n",
    "        (data_continous_binned['previous_binned'] == 'four') &\n",
    "        (data_continous_binned['y'] == 'yes')).astype(int),\n",
    "    'previous_binned_y_3_yes': (\n",
    "        (data_continous_binned['previous_binned'] == 'three') &\n",
    "        (data_continous_binned['y'] == 'yes')).astype(int),\n",
    "    'previous_binned_y_2_yes': (\n",
    "        (data_continous_binned['previous_binned'] == 'two') &\n",
    "        (data_continous_binned['y'] == 'yes')).astype(int)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_binned_interaction_features = pd.DataFrame({\n",
    "    'age_binned_job_15-20_student': (\n",
    "        (data_continous_binned['age_binned'] == '15-20') & \n",
    "        (data_continous_binned['job'] == 'student')).astype(int),\n",
    "    'age_binned_job_20-30_student': (\n",
    "        (data_continous_binned['age_binned'] == '20-30') & \n",
    "        (data_continous_binned['job'] == 'student')).astype(int),\n",
    "    'age_binned_job_60-70_retired': (\n",
    "        (data_continous_binned['age_binned'] == '60-70') & \n",
    "        (data_continous_binned['job'] == 'retired')).astype(int),\n",
    "    'age_binned_job_70+_retired': (\n",
    "        (data_continous_binned['age_binned'] == '70+') & \n",
    "        (data_continous_binned['job'] == 'retired')).astype(int),\n",
    "    'age_binned_edu_15-20_unknown': (\n",
    "        (data_continous_binned['age_binned'] == '15-20') & \n",
    "        (data_continous_binned['education'] == 'unknown')).astype(int),\n",
    "    'age_binned_edu_70+_basic.4y': (\n",
    "        (data_continous_binned['age_binned'] == '70+') & \n",
    "        (data_continous_binned['education'] == 'basic.4y')).astype(int),\n",
    "    'age_binned_edu_70+_iliterate': (\n",
    "        (data_continous_binned['age_binned'] == '70+') & \n",
    "        (data_continous_binned['education'] == 'illiterate')).astype(int),\n",
    "    'age_binned_month_15-20_dec': (\n",
    "        (data_continous_binned['age_binned'] == '15-20') & \n",
    "        (data_continous_binned['month'] == 'dec')).astype(int),\n",
    "    'age_binned_month_15-20_sep': (\n",
    "        (data_continous_binned['age_binned'] == '15-20') & \n",
    "        (data_continous_binned['month'] == 'sep')).astype(int),\n",
    "    'age_binned_month_60-70_dec': (\n",
    "        (data_continous_binned['age_binned'] == '60-70') & \n",
    "        (data_continous_binned['month'] == 'dec')).astype(int),\n",
    "    'age_binned_month_60-70_mar': (\n",
    "        (data_continous_binned['age_binned'] == '60-70') & \n",
    "        (data_continous_binned['month'] == 'mar')).astype(int),\n",
    "    'age_binned_month_60-70_oct': (\n",
    "        (data_continous_binned['age_binned'] == '60-70') & \n",
    "        (data_continous_binned['month'] == 'oct')).astype(int),\n",
    "    'age_binned_month_60-70_sep': (\n",
    "        (data_continous_binned['age_binned'] == '60-70') & \n",
    "        (data_continous_binned['month'] == 'sep')).astype(int),\n",
    "    'age_binned_month_70+_dec': (\n",
    "        (data_continous_binned['age_binned'] == '70+') & \n",
    "        (data_continous_binned['month'] == 'dec')).astype(int),\n",
    "    'age_binned_month_70+_mar': (\n",
    "        (data_continous_binned['age_binned'] == '70+') & \n",
    "        (data_continous_binned['month'] == 'mar')).astype(int),\n",
    "    'age_binned_month_70+_oct': (\n",
    "        (data_continous_binned['age_binned'] == '70+') & \n",
    "        (data_continous_binned['month'] == 'oct')).astype(int),\n",
    "    'age_binned_month_70+_sep': (\n",
    "        (data_continous_binned['age_binned'] == '70+') & \n",
    "        (data_continous_binned['month'] == 'sep')).astype(int),\n",
    "    'age_binned_poutcome_15-20_success': (\n",
    "        (data_continous_binned['age_binned'] == '15-20') & \n",
    "        (data_continous_binned['poutcome'] == 'success')).astype(int),\n",
    "    'age_binned_poutcome_60-70_success': (\n",
    "        (data_continous_binned['age_binned'] == '60-70') & \n",
    "        (data_continous_binned['poutcome'] == 'success')).astype(int),\n",
    "    'age_binned_poutcome_70+_success': (\n",
    "        (data_continous_binned['age_binned'] == '70+') & \n",
    "        (data_continous_binned['poutcome'] == 'success')).astype(int),    \n",
    "    'age_binned_pdays_binned_15-20_0-5': (\n",
    "        (data_continous_binned['age_binned'] == '15-20') & \n",
    "        (data_continous_binned['pdays_binned'] == '0-5')).astype(int),\n",
    "    'age_binned_pdays_binned_15-20_10-15': (\n",
    "        (data_continous_binned['age_binned'] == '15-20') & \n",
    "        (data_continous_binned['pdays_binned'] == '10-15')).astype(int),\n",
    "    'age_binned_pdays_binned_15-20_15-20': (\n",
    "        (data_continous_binned['age_binned'] == '15-20') & \n",
    "        (data_continous_binned['pdays_binned'] == '15-20')).astype(int),\n",
    "    'age_binned_pdays_binned_15-20_5-10': (\n",
    "        (data_continous_binned['age_binned'] == '15-20') & \n",
    "        (data_continous_binned['pdays_binned'] == '5-10')).astype(int),\n",
    "    'age_binned_pdays_binned_60-70_0-5': (\n",
    "        (data_continous_binned['age_binned'] == '60-70') & \n",
    "        (data_continous_binned['pdays_binned'] == '0-5')).astype(int),\n",
    "    'age_binned_pdays_binned_60-70_10-15': (\n",
    "        (data_continous_binned['age_binned'] == '60-70') & \n",
    "        (data_continous_binned['pdays_binned'] == '10-15')).astype(int),\n",
    "    'age_binned_pdays_binned_60-70_15-20': (\n",
    "        (data_continous_binned['age_binned'] == '60-70') & \n",
    "        (data_continous_binned['pdays_binned'] == '15-20')).astype(int),\n",
    "    'age_binned_pdays_binned_60-70_20-25': (\n",
    "        (data_continous_binned['age_binned'] == '60-70') & \n",
    "        (data_continous_binned['pdays_binned'] == '20-25')).astype(int),\n",
    "    'age_binned_pdays_binned_60-70_5-10': (\n",
    "        (data_continous_binned['age_binned'] == '60-70') & \n",
    "        (data_continous_binned['pdays_binned'] == '5-10')).astype(int),\n",
    "    'age_binned_pdays_binned_70+_5-10': (\n",
    "        (data_continous_binned['age_binned'] == '70+') & \n",
    "        (data_continous_binned['pdays_binned'] == '5-10')).astype(int),\n",
    "    'age_binned_pdays_binned_70+_0-5': (\n",
    "        (data_continous_binned['age_binned'] == '70+') & \n",
    "        (data_continous_binned['pdays_binned'] == '0-5')).astype(int),\n",
    "    'age_binned_pdays_binned_70+_10-15': (\n",
    "        (data_continous_binned['age_binned'] == '70+') & \n",
    "        (data_continous_binned['pdays_binned'] == '10-15')).astype(int),\n",
    "    'age_binned_y_70+_yes': (\n",
    "        (data_continous_binned['age_binned'] == '70+') &\n",
    "        (data_continous_binned['y'] == 'yes')).astype(int),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enginnered_data = pd.concat([\n",
    "    data,\n",
    "    binned_continous_features,\n",
    "    interaction_features, \n",
    "    pdays_binned_interaction_features, \n",
    "    campaign_binned_interaction_feaures, \n",
    "    previous_binned_interaction_features, \n",
    "    age_binned_interaction_features\n",
    "    ], axis=1)\n",
    "\n",
    "# Export combined data as csv file\n",
    "# enginnered_data.to_csv(path_or_buf='../data/bank-additional/bank_engineered.csv',\n",
    "#                        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41176, 167)\n"
     ]
    }
   ],
   "source": [
    "print(enginnered_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41176, 165)\n",
      "(41176,)\n"
     ]
    }
   ],
   "source": [
    "# Spliting data into X and y after feature engineering\n",
    "X = enginnered_data.drop(['y', 'duration'], axis=1)\n",
    "y = enginnered_data['y']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "# Label encode the target\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "numerical_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "binary_features = X.select_dtypes(include=['int32']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(\n",
    "            handle_unknown='ignore', \n",
    "            sparse_output=False), categorical_features),\n",
    "        ('bin', 'passthrough', binary_features)\n",
    "    ])\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Get feature names\n",
    "num_features_transformed = numerical_features\n",
    "ohe = preprocessor.named_transformers_['cat']\n",
    "cat_features_transformed = ohe.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine all feature names\n",
    "all_features = np.concatenate([num_features_transformed, \n",
    "                               cat_features_transformed, \n",
    "                               binary_features])\n",
    "\n",
    "# Convert to DataFrame with column names\n",
    "X_transformed_df = pd.DataFrame(X_transformed, columns=all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train: (32940, 228)\n",
      "X Test: (8236, 228)\n",
      "Y Train: (32940,)\n",
      "Y Test: (8236,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_transformed_df, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42)\n",
    "\n",
    "print(\"X Train:\", X_train.shape)\n",
    "print(\"X Test:\", X_test.shape)\n",
    "print(\"Y Train:\", y_train.shape)\n",
    "print(\"Y Test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features selected: 76\n",
      "Best C parameter: 0.615848211066026\n",
      "Training ROC AUC: 0.8170033224101279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr = LogisticRegression(solver='liblinear',\n",
    "                        penalty='l1',\n",
    "                        max_iter=10000, \n",
    "                        class_weight='balanced', \n",
    "                        random_state=42)\n",
    "\n",
    "# Define the Stratified K-Fold cross-validator\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the hyperparameters and their values to search\n",
    "param_grid = {'C': np.logspace(-4, 4, 20)}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "gs = GridSearchCV(estimator=lr,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='roc_auc',\n",
    "                  cv=stratified_kfold,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "best_model = gs.best_estimator_\n",
    "\n",
    "# Get the coefficients of the best model\n",
    "coefficients = best_model.coef_.ravel()\n",
    "    \n",
    "# Identify non-zero coefficients\n",
    "non_zero_indices = np.where(coefficients != 0)[0]\n",
    "\n",
    "print(f\"Number of features selected: {len(non_zero_indices)}\")\n",
    "print(f\"Best C parameter: {gs.best_params_['C']}\")\n",
    "print(f\"Training ROC AUC: {gs.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imp = X_transformed_df.iloc[:, non_zero_indices]\n",
    "\n",
    "imp_data = pd.concat([X_imp, data['y']], axis=1)\n",
    "\n",
    "# imp_data.to_csv(path_or_buf='../data/bank-additional/bank_processed_data.csv',\n",
    "#                 index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance after Feature Engineering and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train: (32940, 76)\n",
      "X Test: (8236, 76)\n",
      "Y Train: (32940,)\n",
      "Y Test: (8236,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_imp, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42)\n",
    "\n",
    "print(\"X Train:\", X_train.shape)\n",
    "print(\"X Test:\", X_test.shape)\n",
    "print(\"Y Train:\", y_train.shape)\n",
    "print(\"Y Test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV ROC AUC Score: 0.817 +/- 0.008\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=42,\n",
    "                        class_weight='balanced',\n",
    "                        max_iter=10000)\n",
    "\n",
    "# Define the Stratified K-Fold cross-validator\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "scores = cross_val_score(lr,\n",
    "                         X_train, y_train, \n",
    "                         cv=stratified_kfold, \n",
    "                         scoring='roc_auc')\n",
    "\n",
    "print(f\"CV ROC AUC Score: {np.mean(scores):.3f} +/- {np.std(scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights and Justifications:\n",
    "\n",
    "### Rationale for chosen features.\n",
    "\n",
    "The chosen features were derived through a methodical process aimed at uncovering and leveraging the inherent relationships within the data:\n",
    "\n",
    "- **Interaction Terms**: Interaction terms were created between pairs of categorical variables where one level of a variable was highly correlated with a level of another. A custom function, `categorical_levels_corr()`, was developed during the data exploration phase to identify possible interactions among pairs of features. This function uses a threshold parameter to determine significant relationships, and a threshold of 3.99 was chosen to decide which interactions to include as new features. This approach helps to capture the combined effect of these categories on the target variable, which might not be evident when considering the individual variables separately.\n",
    "\n",
    "- **Binning Continuous Features**: Continuous features were binned into categorical ones to reduce the impact of outliers and to allow the model to better capture non-linear relationships. This also helps in simplifying the model, making it more interpretable and robust.\n",
    "\n",
    "- **L1 Regularization**: After generating a large number of features (167), and One Hot Encoding categorical features (total features became 228), L1 regularization was applied to select the most important features by shrinking less important feature coefficients to zero. This not only helped in reducing the dimensionality of the model but also in focusing on the features that contribute the most to model accuracy.\n",
    "\n",
    "- **Removal of Duration**: The duration feature was removed during this phase due to the following note provided in the data description:\n",
    "\n",
    "    “duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y=\"no\"). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.”\n",
    "\n",
    "    Including duration in the model results in an unrealistically high ROC AUC score, as it directly correlates with the outcome and is not available before making a prediction. Therefore, it was discarded to ensure the development of a realistic predictive model.\n",
    "\n",
    "### Impact of new features on model performance.\n",
    "\n",
    "The introduction of new features through interaction terms and binning, followed by feature selection using L1 regularization, had a significant positive impact on model performance. Before feature engineering, the average ROC AUC score was 0.791, indicating that the model had some ability to distinguish between classes but was not optimal. After feature engineering and regularization, the ROC AUC score improved to 0.817. This improvement suggests that the engineered features helped the model capture more relevant patterns in the data, thereby improving its predictive accuracy, especially in the presence of class imbalance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
